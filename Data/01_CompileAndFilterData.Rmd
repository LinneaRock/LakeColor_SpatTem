---
title: "Untitled"
author: "Jordan Von Eggers"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# load packages
```{r}
library(tidyverse)
library(sf)
library(nhdplusTools)
library(USAboundaries)
```


# subset Limnosat lakes > 10 ha for Georgia and Texas
```{r, eval = F, warning = F}
## Read in the geospatial data from Hydrolakes
# Lakes
lakes <- st_read('Data/HydroLakes/HydroLakes_DP.shp') %>%
  st_centroid() %>%
  filter(type == 'dp') # Grab only deepest point data
ggplot() +
  geom_sf(lakes, mapping=aes(), size=0.5)

#Get Texas and Georgia outlines
tx_ga <- us_states() %>%
  filter(state_abbr %in% c('TX', 'GA')) %>%
  st_transform(st_crs(lakes))

ggplot() +
  geom_sf(tx_ga, mapping=aes())


tx_ga_lakes <- lakes[tx_ga,] 
ggplot() +
  geom_sf(tx_ga_lakes, mapping=aes(),size=0.5)

ggplot() +
  geom_sf(lakes, mapping=aes(), color='grey') +
  geom_sf(tx_ga_lakes, mapping=aes(), color='red')


# #LimnoSat color data
# ls_tx_ga <- read_csv("C:/Users/lrock1/Downloads/srCorrected_us_hydrolakes_dp_20200628.csv") %>%
#  # mutate(Hylak_id = as.character(Hylak_id)) |>
#   filter(Hylak_id %in% tx_ga_lakes$Hylak_id) %>%
#   inner_join(tx_ga_lakes %>%
#                as.data.frame(.) %>%
#                select(-geometry) %>%
#                select(Hylak_id))
# 
# length(unique(ls_tx_ga$Hylak_id)) # 2456
#save(ls_tx_ga, tx_ga_lakes, file = 'data/ls_elev.RData')

length(unique(tx_ga_lakes$Hylak_id))
# 2495 hydrolakes - not limnosat
  

```


### Join to NHD features

```{r, eval = F}

singular_fetch <- function(index = 1){
  
  wbd <- try(get_waterbodies(tx_ga_lakes[index,]), silent = T)
  
  if(length(class(wbd)) == 1){
    wbd <- NULL
  } else {
    wbd <- wbd %>%
      dplyr::select(comid:onoffnet,meandepth,maxdepth) %>%
      mutate(onoffnet = as.character(onoffnet),
             meandepth = as.numeric(meandepth),
             maxdepth = as.numeric(maxdepth))
  }
  
  return(wbd)
}

full_fetch <- map(1:nrow(tx_ga_lakes),singular_fetch)



full_nhd <- do.call('rbind',full_fetch)


definitely_lakes <- tx_ga_lakes[full_nhd,] 

count_dL <- definitely_lakes |>
  count(Hylak_id) # 1802 unique lakes, no duplicate Hylak_id

library(mapview)
mapview(full_nhd)

nhd_hylak_duplicated <- st_join(definitely_lakes,
                     full_nhd )
#Remove lakes that join to multiple NHDs. Impossible to resolve which numbers to take
#from lake cat
# below are comids that we do not want because they are duplicated as SwampMarsh
count_dups <- nhd_hylak_duplicated |>
  distinct() |>
  group_by(Hylak_id) |>
  mutate(dups= n()) |>
  ungroup() |>
  filter(dups>1) |>
  filter(ftype=='SwampMarsh')


nhd_hylak_nodupes <- anti_join(as.data.frame(nhd_hylak_duplicated), as.data.frame(count_dups)) |>
 distinct() |>
  group_by(Hylak_id) |>
  mutate(dups= n()) |>
  ungroup()  |>
  mutate(comid=as.character(comid))

lake_link <- readRDS('Data/lake_link.RDS') |>
  drop_na(nhdplusv2_comid) |>
  distinct(lagoslakeid, nhdplusv2_comid, .keep_all = T) |>
  mutate(comid=as.character(nhdplusv2_comid),
         lake_nhdid=as.character(lake_nhdid))|>
  select(-nhdplusv2_comid)
head(lake_link)
str(lake_link)


nhd_link <- inner_join(lake_link, nhd_hylak_nodupes, by='comid') |>
  distinct() |>
  group_by(Hylak_id) |>
  mutate(dups_hylak= n()) |>
  ungroup()  |>
  group_by(lake_nhdid) |>
  mutate(dups_nhd= n()) |>
  ungroup()

nhd_link_nodupes <- nhd_link |>
  filter(dups_hylak==1 &
           dups_nhd==1) 

length(unique(nhd_link_nodupes$lake_nhdid))
length(unique(nhd_link_nodupes$lagoslakeid))
length(unique(nhd_link_nodupes$Hylak_id))

#LimnoSat color data
ls_tx_ga <- read_csv("C:/Users/lrock1/Downloads/srCorrected_us_hydrolakes_dp_20200628.csv")  |>  
  inner_join(as.data.frame(nhd_link_nodupes) %>%
               as.data.frame(.) %>%
               select(-geometry))|>
  select(lagoslakeid, lake_nhdid, LandsatID, date, year, dWL) 

  

rm(list=setdiff(ls(), c('ls_tx_ga')))
write.csv(ls_tx_ga, 'ls_tx_ga.csv')
```


